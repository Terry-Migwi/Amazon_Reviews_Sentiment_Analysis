{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19ycE_PuVRihC_EF42K29zLFqpsedK6uy",
      "authorship_tag": "ABX9TyPvtWKXN5KGUisuY+WTjuRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Terry-Migwi/Sentiment_Analysis/blob/main/ML_CDs_Vinyl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the data analytic question\n",
        "\n",
        "The objective of this notebook is to perform classification of sentiment reviews for CDs and Vinyl products using Machine Learning Algorithms. The algorithms used for classification are Logistic Regression, Naive Bayes, Random Forest, and Support Vector Machines."
      ],
      "metadata": {
        "id": "0ZATbOQGcO49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Java and Spark\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "iPSBeOUbM5xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the paths\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "pVmlegjiM9jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Spark session\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark.conf.set(\"spark.sql.caseSensitive\", True) # Avoid error \"Found duplicate column(s) in the data schema\"\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "4NXHl2EpNArE",
        "outputId": "f7fddaba-a6c0-4689-a2f1-9f22f0920061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fe1087a5330>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://361268695ba3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qbDJKBkMmHL",
        "outputId": "9d0f6172-7af4-459c-f8d0-50a00d681666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-------+--------------------+-----------+--------------+----------------+-----+--------------------+--------------+--------+----+\n",
            "|      asin|image|overall|          reviewText| reviewTime|    reviewerID|    reviewerName|style|             summary|unixReviewTime|verified|vote|\n",
            "+----------+-----+-------+--------------------+-----------+--------------+----------------+-----+--------------------+--------------+--------+----+\n",
            "|0001393774| null|    5.0|Love it!!  Great ...|04 29, 2016|A1H1DL4K669VQ9| Judith Paladino| null|          Five Stars|    1461888000|    true|null|\n",
            "|0001393774| null|    5.0|One of my very fa...|02 23, 2016|A3V5XBBT7OZG5G|          gflady| null|One of my very fa...|    1456185600|    true|null|\n",
            "|0001393774| null|    5.0|THank you Jesus L...|02 11, 2016|A3SNL7UJY7GWBI|Lady Leatherneck| null|          Five Stars|    1455148800|    true|null|\n",
            "|0001393774| null|    5.0|I recall loving h...|11 28, 2015|A3478QRKQDOPQ2|           jacki| null|forgot but I figu...|    1448668800|    true|null|\n",
            "|0001393774| null|    5.0|Keith Green was a...|12 16, 2014|A23M5VTSN2C3H1|         Caliope| null|and I have loved ...|    1418688000|    true|null|\n",
            "+----------+-----+-------+--------------------+-----------+--------------+----------------+-----+--------------------+--------------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "myReview = spark.read.json(\"/content/drive/MyDrive/Colab Notebooks/CDs_and_Vinyl_5.json.gz\")\n",
        "\n",
        "# Take a look\n",
        "myReview.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# manually create positive and negative reviews\n",
        "from pyspark.sql import functions as f\n",
        "\n",
        "# Set up sentiment column based on rating\n",
        "myData = myReview.withColumn(\n",
        "    # Name a new column\n",
        "    \"sentiment\",\n",
        "    # Use \"when\" for conditional setup\n",
        "    f.when((f.col(\"overall\") >=4),\"positive\")\n",
        "    # neutral sentiment\n",
        "    .when((f.col(\"overall\") == 3), \"neutral\")\n",
        "    # Negative coded as\n",
        "    .when((f.col(\"overall\") <=2),\"negative\")\n",
        "    )"
      ],
      "metadata": {
        "id": "Kst5wU5KNkil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look\n",
        "\n",
        "myData.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7OkateiOXTM",
        "outputId": "e806dc3f-4b7e-4404-d8ef-7494a96cd0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-------+--------------------+-----------+--------------+-------------------+------------+--------------------+--------------+--------+----+---------+\n",
            "|      asin|image|overall|          reviewText| reviewTime|    reviewerID|       reviewerName|       style|             summary|unixReviewTime|verified|vote|sentiment|\n",
            "+----------+-----+-------+--------------------+-----------+--------------+-------------------+------------+--------------------+--------------+--------+----+---------+\n",
            "|0001393774| null|    5.0|Love it!!  Great ...|04 29, 2016|A1H1DL4K669VQ9|    Judith Paladino|        null|          Five Stars|    1461888000|    true|null| positive|\n",
            "|0001393774| null|    5.0|One of my very fa...|02 23, 2016|A3V5XBBT7OZG5G|             gflady|        null|One of my very fa...|    1456185600|    true|null| positive|\n",
            "|0001393774| null|    5.0|THank you Jesus L...|02 11, 2016|A3SNL7UJY7GWBI|   Lady Leatherneck|        null|          Five Stars|    1455148800|    true|null| positive|\n",
            "|0001393774| null|    5.0|I recall loving h...|11 28, 2015|A3478QRKQDOPQ2|              jacki|        null|forgot but I figu...|    1448668800|    true|null| positive|\n",
            "|0001393774| null|    5.0|Keith Green was a...|12 16, 2014|A23M5VTSN2C3H1|            Caliope|        null|and I have loved ...|    1418688000|    true|null| positive|\n",
            "|0001393774| null|    5.0|Keith Green, amaz...| 11 4, 2014|A1DOF5GHOWGMW6|                  p|        null|            FABULOUS|    1415059200|    true|null| positive|\n",
            "|0001393774| null|    5.0|       VERY GOOD CD.| 08 2, 2014| AJVC0VFJKOYWU|     Elaine Persing|        null|          Five Stars|    1406937600|   false|null| positive|\n",
            "|0001393774| null|    5.0|i love this cd i ...| 04 7, 2014|A2MRQG8RN5JI7R|             janice|        null|songs for the shs...|    1396828800|    true|null| positive|\n",
            "|0001393774| null|    5.0|Keith Green / Son...| 01 9, 2012|A12R54MKO17TW0|           J. Bynum|        null|His last album is...|    1326067200|   false|null| positive|\n",
            "|0001393774| null|    5.0|Keith Green had a...| 11 1, 2005| AEKGGV851HY3K|        Avid Reader|        null|Passionate Faith ...|    1130803200|   false|null| positive|\n",
            "|0005164885| null|    5.0|Christmas and TSO...|02 22, 2018|A2LBDC9ZGSCAE6|              Kevin| { Audio CD}|TSO...what more d...|    1519257600|    true|null| positive|\n",
            "|0005164885| null|    4.0|                good|02 14, 2018|A2ZB6AHRM0ZLLW| Herbert B Brady jr| { Audio CD}|          Four Stars|    1518566400|    true|null| positive|\n",
            "|0005164885| null|    5.0|good sound for th...|02 10, 2018|A1LU1VWVVCU85F|sharon l. wachowski| { Audio CD}|                nice|    1518220800|    true|null| positive|\n",
            "|0005164885| null|    5.0|Item arrived quic...|01 28, 2018|A3VUWBZF2U32TJ|                Deb| { Audio CD}|          Five Stars|    1517097600|    true|null| positive|\n",
            "|0005164885| null|    5.0|         Great album|01 10, 2018| AV3DKV2TW5B3C|            Darrell| { Audio CD}|          Five Stars|    1515542400|    true|null| positive|\n",
            "|0005164885| null|    5.0|We are repeat off...|12 25, 2017|A1M9ZQQIX4JM6D|        S+S Florida|{ MP3 Music}|Wonderful and Pow...|    1514160000|   false|null| positive|\n",
            "|0005164885| null|    5.0|Another great mus...|12 23, 2017|A30N79HHDW8LMA|          D. Ramsey| { Audio CD}|If you are young ...|    1513987200|    true|null| positive|\n",
            "|0005164885| null|    5.0|My first Trans-si...|12 21, 2017|A20UGR9OYQL7A4|     Kelli Meredith| { Audio CD}|A True Christmas ...|    1513814400|    true|null| positive|\n",
            "|0005164885| null|    5.0|           love this|10 12, 2017|A1JPE1PWL7I2CN|   Anthony Ferguson| { Audio CD}|          Five Stars|    1507766400|    true|null| positive|\n",
            "|0005164885| null|    5.0|         great album|09 14, 2017|A1X6T2KY30WG3D|        Linda Brady| { Audio CD}|          Five Stars|    1505347200|    true|null| positive|\n",
            "+----------+-----+-------+--------------------+-----------+--------------+-------------------+------------+--------------------+--------------+--------+----+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# explore the sentiment column\n",
        "\n",
        "# Get an idea of sentiment distribution\n",
        "\n",
        "myData.groupBy(\"sentiment\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "4b7sd5N7Ockz",
        "outputId": "70a33f39-4f85-4613-8947-6f8afc80e439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+-------+\n",
              "|sentiment|  count|\n",
              "+---------+-------+\n",
              "| positive|1243486|\n",
              "|  neutral| 110407|\n",
              "| negative|  89862|\n",
              "+---------+-------+"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>sentiment</th><th>count</th></tr>\n",
              "<tr><td>positive</td><td>1243486</td></tr>\n",
              "<tr><td>neutral</td><td>110407</td></tr>\n",
              "<tr><td>negative</td><td>89862</td></tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view review text\n",
        "myData.select(\"reviewText\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtEYXaBOQYDu",
        "outputId": "58ccce4b-8181-4988-c398-15cf146d8bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|reviewText                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Love it!!  Great seller!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "|One of my very favourite albums from one of my very favourite singers.  I was happy to see I could replace the old worn cassettes from years ago.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "|THank you Jesus Lord God, that brother Green's music is still sounding though he is Home with you now.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "|I recall loving his other albums and maybe this one too, forgot but I figured on some of these artists seems like one good album and all good albums..especially in Christian music..seemed when they got into it they stayed into it and so good to double check though if want too but it is a possible very good album because I usually recall if too bad of one and I don't on this one                                                                                                                                                                                                                                                                                                            |\n",
            "|Keith Green was a pioneer in the field of Christian rock, and I have loved every album he did.  This one is particularly sweet as he was just coming into his own as a premier music writer and performer when it was published.  His loss was a terrible blow for millions of his fans.                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "|Keith Green, amazing gift God gave him!!!  Draw near to God as his music brings you into God's presence.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "|VERY GOOD CD.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|i love this cd i had a cassette so had to get a cd the songs have so much\\nmeaning and i think of the children that were lost. love it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "|Keith Green / Songs for the Shepherd:  His previous albums were more focused on encouragement and correction towards the Church.  This, his last, is focused on Praise.  This one is still not as great as his first album, but it is a strong enough Praise album to earn Five Stars.                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "|Keith Green had a passionate love for Jesus.  This is evident in his life as well as in his music.  He didn't preach Jesus at concerts sponsored by beer companies.  He didn't get divorced and remarried.  He didn't live a life of luxury off of his royalties while billions starved.  He was the real deal.  He was a real Christian.\\n\\nMuch of his music consists of love songs to God, and listening to this music Keith's love for Jesus encourages me.  Hearing the tender serenades of a true lover of Jesus fans the flame of the listener's own passion.  It's contagious.                                                                                                                  |\n",
            "|Christmas and TSO just goes together like Rudolph and Santa!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "|good                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "|good sound for the holiday                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "|Item arrived quickly and was as described!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "|Great album                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|We are repeat offenders when it comes to TSO concerts and each time the experience is even grander than before. The concert on December 17th 2017 in Tampa was a spectacle that I can replay in my mind over and over again. The music touches the soul and goes to right the core; the whole show is visceral and the artists all perform with all their enthusiasm and love what they do. The light-show, the pyro-effects, and the moving parts on stage are amazing and take your breath away. This display of powerful music, magical storytelling, and a dazzling light- and laser-show is  in my opinion  one of the must-see shows and one of the top performances the music world has to offer.|\n",
            "|Another great music performance by Trans-Siberian Orchestra! This music makes me want to get out my notebook and start writing music again! I love the guitars and their jamming but in a way it all fits with the rest of the singers and instruments. Can' t think of anything I didn't like.                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|My first Trans-siberian CD! It is for everyone,  with soft and vibrant vocals to the jazzy orchestra instrumentals! Don't hesitate to get this CD!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|love this                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|great album                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view summary\n",
        "myData.select(\"summary\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn3CS4uxSors",
        "outputId": "ba8290af-4c9b-4e34-9610-b2428a149d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------+\n",
            "|summary                                                                                                                      |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------+\n",
            "|Five Stars                                                                                                                   |\n",
            "|One of my very favourite albums from one of my very favourite singers                                                        |\n",
            "|Five Stars                                                                                                                   |\n",
            "|forgot but I figured on some of these artists seems like one good album and all good albums                                  |\n",
            "|and I have loved every album he did                                                                                          |\n",
            "|FABULOUS                                                                                                                     |\n",
            "|Five Stars                                                                                                                   |\n",
            "|songs for the shsephers                                                                                                      |\n",
            "|His last album is focused on Praise                                                                                          |\n",
            "|Passionate Faith Is Contagious                                                                                               |\n",
            "|TSO...what more do you need to know?                                                                                         |\n",
            "|nice                                                                                                                         |\n",
            "|Five Stars                                                                                                                   |\n",
            "|Five Stars                                                                                                                   |\n",
            "|Wonderful and Powerful Songs                                                                                                 |\n",
            "|If you are young at heart and love all genres of music, and want to see Christmas become brand new again..this cd is for you!|\n",
            "|A True Christmas Classic CD!                                                                                                 |\n",
            "|Five Stars                                                                                                                   |\n",
            "|Five Stars                                                                                                                   |\n",
            "|Sweet and Soothing                                                                                                           |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tidy up the text data\n",
        "\n",
        "myData = (myData\n",
        "          #Remove handles\n",
        "          .withColumn(\"reviewText\", f.regexp_replace(f.col(\"reviewText\"), \"@[\\w]*\", \"\"))    #delete all words that start with @\n",
        "          #Remove special characters\n",
        "          .withColumn(\"reviewText\", f.regexp_replace(f.col(\"reviewText\"), \"[^a-zA-Z']\", \" \"))   #replaced hyperlinks with spaces. Because they are not aplhanumeric\n",
        "          #Remove leading and trailing whitespaces\n",
        "          .withColumn(\"reviewText\", f.trim(f.col(\"reviewText\")))\n",
        "          #Restrict the length of the string\n",
        "          .filter(f.length(\"reviewText\")>5)\n",
        "          )\n",
        "\n",
        "# use withcolumn to refer to the variable we want to use"
      ],
      "metadata": {
        "id": "z-oq11GwQRHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect a sample for modelling\n",
        "\n",
        "# Get the positive ones\n",
        "myDataPos = myData.filter(\"sentiment = 'positive'\")\n",
        "\n",
        "# Get the negative ones\n",
        "myDataNeg = myData.filter(\"sentiment = 'negative'\")\n",
        "\n",
        "# Get a random sample from positive\n",
        "myDataPosSample = myDataPos.sample(fraction=200/myDataPos.count(), seed=9165)\n",
        "\n",
        "# Get a random sample from negative\n",
        "myDataNegSample = myDataNeg.sample(fraction=200/myDataNeg.count(), seed=9165)\n",
        "\n",
        "# Combine into a single sample\n",
        "mySample = myDataPosSample.union(myDataNegSample)"
      ],
      "metadata": {
        "id": "8TDhQYHGTgwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look\n",
        "\n",
        "mySample.groupBy(\"sentiment\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "8XV59hXNUjWV",
        "outputId": "fecd8072-b3d0-490b-a977-52318aa5deea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+-----+\n",
              "|sentiment|count|\n",
              "+---------+-----+\n",
              "| positive|  212|\n",
              "| negative|  228|\n",
              "+---------+-----+"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>sentiment</th><th>count</th></tr>\n",
              "<tr><td>positive</td><td>212</td></tr>\n",
              "<tr><td>negative</td><td>228</td></tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a split 80 /20\n",
        "\n",
        "(training, test) = mySample.randomSplit([0.8, 0.2],seed = 9165)"
      ],
      "metadata": {
        "id": "xpqdN-vXUlvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "jzYuKbg0bMRA",
        "outputId": "16e9d9c1-9b6d-41d2-a04e-a3e920308724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+----------+-----+-------+--------------------+-----------+--------------+-------------------+------------+--------------------+--------------+--------+----+---------+\n",
              "|      asin|image|overall|          reviewText| reviewTime|    reviewerID|       reviewerName|       style|             summary|unixReviewTime|verified|vote|sentiment|\n",
              "+----------+-----+-------+--------------------+-----------+--------------+-------------------+------------+--------------------+--------------+--------+----+---------+\n",
              "|6305394776| null|    5.0|MAGNIFICENT movie...| 11 5, 2016|A20GQVYYTLJTIW|              suomi|      { DVD}|Brilliantly direc...|    1478304000|    true|null| positive|\n",
              "|B000000H85| null|    5.0|This album is rig...| 03 3, 2003|A3KYERW5V9TQUV|      Total Scumbag| { Audio CD}|          INSANE!!!!|    1046649600|   false|null| positive|\n",
              "|B000000HQR| null|    4.0|         solid album| 10 9, 2015| AKNPR99HNY7KM|            beerguy| { Audio CD}|Japan is worth th...|    1444348800|    true|null| positive|\n",
              "|B000000OC2| null|    5.0|The movie Sister ...|04 13, 2010|A16C9QBZHS9UDO|        Curst Saden| { Audio CD}|         Really Good|    1271116800|    true|null| positive|\n",
              "|B0000012ZQ| null|    5.0|We already have s...|12 21, 2004|A1THJ5GJF9NLCS|               BLee| { Audio CD}|A Life Long Enjoy...|    1103587200|   false|  30| positive|\n",
              "|B000001EMW| null|    5.0|What a great cd  ...| 10 2, 2010|A1YMOZFIXPKU73|            D. Ryan| { Audio CD}|                  CD|    1285977600|    true|null| positive|\n",
              "|B000001ESB| null|    5.0|The second Album ...|08 30, 2015| AU4DJA0QUTAPS|     Seanus Groovus|        null|        Perfection..|    1440892800|    true|null| positive|\n",
              "|B000001F62| null|    5.0|This CD is likely...|05 12, 2003|A2AOZQ3WTNVVOK|   Lonnie E. Holder| { Audio CD}|The Most Progress...|    1052697600|   false|  39| positive|\n",
              "|B000001F68| null|    5.0|Awesome   The new...|04 15, 2018|A1NLZWLIP2GC6W|         R Dee Dee.| { Audio CD}|Awesome! The new ...|    1523750400|    true|null| positive|\n",
              "|B000001FKG| null|    5.0|So what if this a...| 04 4, 2005|A31HTN51QNSQ3F|          Ben Kizer| { Audio CD}|      His best album|    1112572800|   false|null| positive|\n",
              "|B000001FO4| null|    5.0|great mix of slow...|07 17, 2000|A2G8H7OJMBRO61|    Amazon Customer| { Audio CD}|          Good Stuff|     963792000|   false|   3| positive|\n",
              "|B000001FY9| null|    5.0|       great thank's| 06 5, 2015| AE8043AJ67AQX|     thomas  lavoie| { Audio CD}|          Five Stars|    1433462400|    true|null| positive|\n",
              "|B000001M6N| null|    5.0|         Great songs|07 23, 2014|A2P3A0SLOEDOHJ|              Nurse|{ MP3 Music}|        Great songs!|    1406073600|    true|null| positive|\n",
              "|B0000025DP| null|    5.0|The ELO of the fi...|05 11, 2000| ACFTPKBAVA1F8|    Peter A. Greene| { Audio CD}|          ELO's peak|     958003200|   false|null| positive|\n",
              "|B0000025GD| null|    5.0|Dead Ringer is pu...|03 21, 2005|A250BI36M1IR26|          Eric Kent| { Audio CD}|Meat Loaf at this...|    1111363200|   false|   2| positive|\n",
              "|B0000025VY| null|    5.0|As other reviewer...|06 10, 2010| ATLZNVLYKP9AZ|          T. Fisher| { Audio CD}|A great collectio...|    1276128000|   false|null| positive|\n",
              "|B00000273I| null|    5.0|Miles Davis etc  ...|05 21, 2017| AZ8810QMLLH9S|            cibigay| { Audio CD}|          Five Stars|    1495324800|    true|null| positive|\n",
              "|B000002BGM| null|    4.0|The music Journey...|12 15, 2001|A3W4D8XOGLWUN5|     Michael Kerner| { Audio CD}|The Very Last Jou...|    1008374400|   false|  11| positive|\n",
              "|B000002E95| null|    5.0|Maybe Robi Rosa i...|07 24, 2002|A31DVEVB5CVTW6|e.s. ortiz-gonzalez| { Audio CD}|    Enter the Master|    1027468800|   false|   8| positive|\n",
              "|B000002G23| null|    5.0|This is going out...| 12 6, 2006|A3FEQXNCFC68KC|         SRFireside| { Audio CD}|Best collection y...|    1165363200|   false|   7| positive|\n",
              "+----------+-----+-------+--------------------+-----------+--------------+-------------------+------------+--------------------+--------------+--------+----+---------+\n",
              "only showing top 20 rows"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>asin</th><th>image</th><th>overall</th><th>reviewText</th><th>reviewTime</th><th>reviewerID</th><th>reviewerName</th><th>style</th><th>summary</th><th>unixReviewTime</th><th>verified</th><th>vote</th><th>sentiment</th></tr>\n",
              "<tr><td>6305394776</td><td>null</td><td>5.0</td><td>MAGNIFICENT movie...</td><td>11 5, 2016</td><td>A20GQVYYTLJTIW</td><td>suomi</td><td>{ DVD}</td><td>Brilliantly direc...</td><td>1478304000</td><td>true</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B000000H85</td><td>null</td><td>5.0</td><td>This album is rig...</td><td>03 3, 2003</td><td>A3KYERW5V9TQUV</td><td>Total Scumbag</td><td>{ Audio CD}</td><td>INSANE!!!!</td><td>1046649600</td><td>false</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B000000HQR</td><td>null</td><td>4.0</td><td>solid album</td><td>10 9, 2015</td><td>AKNPR99HNY7KM</td><td>beerguy</td><td>{ Audio CD}</td><td>Japan is worth th...</td><td>1444348800</td><td>true</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B000000OC2</td><td>null</td><td>5.0</td><td>The movie Sister ...</td><td>04 13, 2010</td><td>A16C9QBZHS9UDO</td><td>Curst Saden</td><td>{ Audio CD}</td><td>Really Good</td><td>1271116800</td><td>true</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B0000012ZQ</td><td>null</td><td>5.0</td><td>We already have s...</td><td>12 21, 2004</td><td>A1THJ5GJF9NLCS</td><td>BLee</td><td>{ Audio CD}</td><td>A Life Long Enjoy...</td><td>1103587200</td><td>false</td><td>30</td><td>positive</td></tr>\n",
              "<tr><td>B000001EMW</td><td>null</td><td>5.0</td><td>What a great cd  ...</td><td>10 2, 2010</td><td>A1YMOZFIXPKU73</td><td>D. Ryan</td><td>{ Audio CD}</td><td>CD</td><td>1285977600</td><td>true</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B000001ESB</td><td>null</td><td>5.0</td><td>The second Album ...</td><td>08 30, 2015</td><td>AU4DJA0QUTAPS</td><td>Seanus Groovus</td><td>null</td><td>Perfection..</td><td>1440892800</td><td>true</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B000001F62</td><td>null</td><td>5.0</td><td>This CD is likely...</td><td>05 12, 2003</td><td>A2AOZQ3WTNVVOK</td><td>Lonnie E. Holder</td><td>{ Audio CD}</td><td>The Most Progress...</td><td>1052697600</td><td>false</td><td>39</td><td>positive</td></tr>\n",
              "<tr><td>B000001F68</td><td>null</td><td>5.0</td><td>Awesome   The new...</td><td>04 15, 2018</td><td>A1NLZWLIP2GC6W</td><td>R Dee Dee.</td><td>{ Audio CD}</td><td>Awesome! The new ...</td><td>1523750400</td><td>true</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B000001FKG</td><td>null</td><td>5.0</td><td>So what if this a...</td><td>04 4, 2005</td><td>A31HTN51QNSQ3F</td><td>Ben Kizer</td><td>{ Audio CD}</td><td>His best album</td><td>1112572800</td><td>false</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B000001FO4</td><td>null</td><td>5.0</td><td>great mix of slow...</td><td>07 17, 2000</td><td>A2G8H7OJMBRO61</td><td>Amazon Customer</td><td>{ Audio CD}</td><td>Good Stuff</td><td>963792000</td><td>false</td><td>3</td><td>positive</td></tr>\n",
              "<tr><td>B000001FY9</td><td>null</td><td>5.0</td><td>great thank&#x27;s</td><td>06 5, 2015</td><td>AE8043AJ67AQX</td><td>thomas  lavoie</td><td>{ Audio CD}</td><td>Five Stars</td><td>1433462400</td><td>true</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B000001M6N</td><td>null</td><td>5.0</td><td>Great songs</td><td>07 23, 2014</td><td>A2P3A0SLOEDOHJ</td><td>Nurse</td><td>{ MP3 Music}</td><td>Great songs!</td><td>1406073600</td><td>true</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B0000025DP</td><td>null</td><td>5.0</td><td>The ELO of the fi...</td><td>05 11, 2000</td><td>ACFTPKBAVA1F8</td><td>Peter A. Greene</td><td>{ Audio CD}</td><td>ELO&#x27;s peak</td><td>958003200</td><td>false</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B0000025GD</td><td>null</td><td>5.0</td><td>Dead Ringer is pu...</td><td>03 21, 2005</td><td>A250BI36M1IR26</td><td>Eric Kent</td><td>{ Audio CD}</td><td>Meat Loaf at this...</td><td>1111363200</td><td>false</td><td>2</td><td>positive</td></tr>\n",
              "<tr><td>B0000025VY</td><td>null</td><td>5.0</td><td>As other reviewer...</td><td>06 10, 2010</td><td>ATLZNVLYKP9AZ</td><td>T. Fisher</td><td>{ Audio CD}</td><td>A great collectio...</td><td>1276128000</td><td>false</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B00000273I</td><td>null</td><td>5.0</td><td>Miles Davis etc  ...</td><td>05 21, 2017</td><td>AZ8810QMLLH9S</td><td>cibigay</td><td>{ Audio CD}</td><td>Five Stars</td><td>1495324800</td><td>true</td><td>null</td><td>positive</td></tr>\n",
              "<tr><td>B000002BGM</td><td>null</td><td>4.0</td><td>The music Journey...</td><td>12 15, 2001</td><td>A3W4D8XOGLWUN5</td><td>Michael Kerner</td><td>{ Audio CD}</td><td>The Very Last Jou...</td><td>1008374400</td><td>false</td><td>11</td><td>positive</td></tr>\n",
              "<tr><td>B000002E95</td><td>null</td><td>5.0</td><td>Maybe Robi Rosa i...</td><td>07 24, 2002</td><td>A31DVEVB5CVTW6</td><td>e.s. ortiz-gonzalez</td><td>{ Audio CD}</td><td>Enter the Master</td><td>1027468800</td><td>false</td><td>8</td><td>positive</td></tr>\n",
              "<tr><td>B000002G23</td><td>null</td><td>5.0</td><td>This is going out...</td><td>12 6, 2006</td><td>A3FEQXNCFC68KC</td><td>SRFireside</td><td>{ Audio CD}</td><td>Best collection y...</td><td>1165363200</td><td>false</td><td>7</td><td>positive</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the training data\n",
        "\n",
        "# training.groupBy(\"sentiment\").count()"
      ],
      "metadata": {
        "id": "EJd3ySGMU_b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the test data\n",
        "\n",
        "# test.groupBy(\"sentiment\").count()"
      ],
      "metadata": {
        "id": "b1uVYLrlVB-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use nickname feat for the subpackage\n",
        "import pyspark.ml.feature as feat\n",
        "\n",
        "# We need Pipeline to streamline the workflow\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Use logistic regression, naive bayes, and random forests\n",
        "from pyspark.ml.classification import LogisticRegression, NaiveBayes, RandomForestClassifier, LinearSVC, MultilayerPerceptronClassifier\n",
        "\n",
        "# Import an evaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Additional functions for tuning parameters\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ],
      "metadata": {
        "id": "tC-VYxoqW6bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build up the pipeline/workflow for TF-IDF approach\n",
        "\n",
        "# Split the tweets into words\n",
        "splitter = feat.RegexTokenizer(\n",
        "    inputCol='reviewText'\n",
        "    , outputCol='text_split'\n",
        "    , pattern='\\s+'\n",
        ")\n",
        "\n",
        "# Remove stop words\n",
        "sw_remover = feat.StopWordsRemover(\n",
        "    inputCol=splitter.getOutputCol()\n",
        "    , outputCol='text_noSW'\n",
        ")\n",
        "\n",
        "# Count word frequency\n",
        "count_vec = feat.CountVectorizer(\n",
        "    inputCol=sw_remover.getOutputCol()\n",
        "    , outputCol='vector'\n",
        "    , vocabSize=5000\n",
        ")\n",
        "\n",
        "# Calculate IDF\n",
        "idf_cal = feat.IDF(\n",
        "    inputCol=count_vec.getOutputCol()\n",
        "    , outputCol='features'\n",
        "    , minDocFreq=5\n",
        ")\n",
        "\n",
        "# Prepare the target variable\n",
        "label_string = feat.StringIndexer(\n",
        "    inputCol = \"sentiment\"\n",
        "    , outputCol = \"label\"\n",
        ")\n",
        "\n",
        "# Logistic regression model\n",
        "lr = LogisticRegression(\n",
        "    maxIter=100\n",
        ")\n",
        "\n",
        "\n",
        "# Finally set up the pipline\n",
        "sentiment_pipeline_idf_lr = Pipeline(\n",
        "    stages=[\n",
        "            splitter\n",
        "            , sw_remover\n",
        "            , count_vec\n",
        "            , idf_cal\n",
        "            , label_string\n",
        "            , lr\n",
        "            ]\n",
        ")"
      ],
      "metadata": {
        "id": "9OJwj1qGVKmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the parameters to tune\n",
        "parGrid = ParamGridBuilder() \\\n",
        "          .addGrid(count_vec.vocabSize, [3000, 5000]) \\\n",
        "          .addGrid(lr.regParam, [0.1, 5]) \\\n",
        "          .build()\n",
        "\n",
        "# Set up the cross validation\n",
        "crossVal = CrossValidator(estimator=sentiment_pipeline_idf_lr,\n",
        "                          estimatorParamMaps=parGrid,\n",
        "                          evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
        "                          numFolds=10,\n",
        "                          seed=9165)"
      ],
      "metadata": {
        "id": "6UEUCNpsXqoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the process to the training data set\n",
        "\n",
        "cvModel = crossVal.fit(training)"
      ],
      "metadata": {
        "id": "4SiDpmQjYI1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarise nicely the results of different parameter combinations\n",
        "\n",
        "for i in range(len(cvModel.avgMetrics)):\n",
        "  myParam = parGrid[i]\n",
        "  myModel = \"Model parameters: \"\n",
        "  for key, value in myParam.items():\n",
        "    myModel += (key.name + '=' + str(value) + ' ')\n",
        "  print(myModel+\"has average accuracy: \"+str(cvModel.avgMetrics[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T-iBXw9YR11",
        "outputId": "353ed033-2df4-4b14-d93c-df7bf71065bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: vocabSize=3000 regParam=0.1 has average accuracy: 0.6968558969090903\n",
            "Model parameters: vocabSize=3000 regParam=5.0 has average accuracy: 0.631015363747379\n",
            "Model parameters: vocabSize=5000 regParam=0.1 has average accuracy: 0.6968558969090903\n",
            "Model parameters: vocabSize=5000 regParam=5.0 has average accuracy: 0.631015363747379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the best model to the test data set\n",
        "\n",
        "cv_prediction = cvModel.transform(test)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "cv_accuracy = evaluator.evaluate(cv_prediction)\n",
        "print(\"Accuracy of the best Logistic Regression model with the test data is %g\"% (cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCwrcoTudLLG",
        "outputId": "4ad83f4c-0258-4f2c-9e05-77442d073b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the best Logistic Regression model with the test data is 0.736264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "C3zuOUUwdVM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build up the pipeline/workflow for Naive Bayes\n",
        "\n",
        "# Split the tweets into words\n",
        "splitter = feat.RegexTokenizer(\n",
        "    inputCol='reviewText'\n",
        "    , outputCol='text_split'\n",
        "    , pattern='\\s+'\n",
        ")\n",
        "\n",
        "# Remove stop words\n",
        "sw_remover = feat.StopWordsRemover(\n",
        "    inputCol=splitter.getOutputCol()\n",
        "    , outputCol='text_noSW'\n",
        ")\n",
        "\n",
        "# Count word frequency\n",
        "count_vec = feat.CountVectorizer(\n",
        "    inputCol=sw_remover.getOutputCol()\n",
        "    , outputCol='vector'\n",
        ")\n",
        "\n",
        "# Calculate IDF\n",
        "idf_cal = feat.IDF(\n",
        "    inputCol=count_vec.getOutputCol()\n",
        "    , outputCol='features'\n",
        "    , minDocFreq=5\n",
        ")\n",
        "\n",
        "# Prepare the target variable\n",
        "label_string = feat.StringIndexer(\n",
        "    inputCol = \"sentiment\"\n",
        "    , outputCol = \"label\"\n",
        ")\n",
        "\n",
        "# Naive Bayes model\n",
        "nb = NaiveBayes(\n",
        ")\n",
        "\n",
        "\n",
        "# Finally set up the pipline\n",
        "sentiment_pipeline_idf_nb = Pipeline(\n",
        "    stages=[\n",
        "            splitter\n",
        "            , sw_remover\n",
        "            , count_vec\n",
        "            , idf_cal\n",
        "            , label_string\n",
        "            , nb\n",
        "            ]\n",
        ")"
      ],
      "metadata": {
        "id": "l0uj54sQdTFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the parameters to tune\n",
        "parGrid = ParamGridBuilder() \\\n",
        "          .addGrid(count_vec.vocabSize, [3000, 5000]) \\\n",
        "          .addGrid(nb.smoothing, [1, 0]) \\\n",
        "          .build()\n",
        "\n",
        "# Set up the cross validation\n",
        "crossVal = CrossValidator(estimator=sentiment_pipeline_idf_nb,\n",
        "                          estimatorParamMaps=parGrid,\n",
        "                          evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
        "                          numFolds=10,\n",
        "                          seed=9165)"
      ],
      "metadata": {
        "id": "fFyrfjKUdc6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the process to the training data set\n",
        "\n",
        "cvModel = crossVal.fit(training)"
      ],
      "metadata": {
        "id": "UhwSbGwgdiBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarise nicely the results of different parameter combinations\n",
        "\n",
        "for i in range(len(cvModel.avgMetrics)):\n",
        "  myParam = parGrid[i]\n",
        "  myModel = \"Model parameters: \"\n",
        "  for key, value in myParam.items():\n",
        "    myModel += (key.name + '=' + str(value) + ' ')\n",
        "  print(myModel+\"has average accuracy: \"+str(cvModel.avgMetrics[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUe8px5ydmdE",
        "outputId": "31251a7c-fd2f-4768-eb4e-8cb6f3cd55f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: vocabSize=3000 smoothing=1.0 has average accuracy: 0.6486509720946829\n",
            "Model parameters: vocabSize=3000 smoothing=0.0 has average accuracy: 0.4962947666479634\n",
            "Model parameters: vocabSize=5000 smoothing=1.0 has average accuracy: 0.6408432841099689\n",
            "Model parameters: vocabSize=5000 smoothing=0.0 has average accuracy: 0.4962947666479634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the best model to the test data set\n",
        "\n",
        "cv_prediction = cvModel.transform(test)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "cv_accuracy = evaluator.evaluate(cv_prediction)\n",
        "print(\"Accuracy of the best Naive Bayes model with the test data is %g\"% (cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK2c9Nnldqcv",
        "outputId": "cc9bf522-de96-44dc-b528-9a354ef7ca9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the best Naive Bayes model with the test data is 0.648352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forests"
      ],
      "metadata": {
        "id": "3eU6Z8IHfBTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build up the pipeline/workflow for Random Forest\n",
        "\n",
        "# Split the tweets into words\n",
        "splitter = feat.RegexTokenizer(\n",
        "    inputCol='reviewText'\n",
        "    , outputCol='text_split'\n",
        "    , pattern='\\s+'\n",
        ")\n",
        "\n",
        "# Remove stop words\n",
        "sw_remover = feat.StopWordsRemover(\n",
        "    inputCol=splitter.getOutputCol()\n",
        "    , outputCol='text_noSW'\n",
        ")\n",
        "\n",
        "# Count word frequency\n",
        "count_vec = feat.CountVectorizer(\n",
        "    inputCol=sw_remover.getOutputCol()\n",
        "    , outputCol='vector'\n",
        ")\n",
        "\n",
        "# Calculate IDF\n",
        "idf_cal = feat.IDF(\n",
        "    inputCol=count_vec.getOutputCol()\n",
        "    , outputCol='features'\n",
        "    , minDocFreq=5\n",
        ")\n",
        "\n",
        "# Prepare the target variable\n",
        "label_string = feat.StringIndexer(\n",
        "    inputCol = \"sentiment\"\n",
        "    , outputCol = \"label\"\n",
        ")\n",
        "\n",
        "# Random forest model\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "\n",
        "# Finally set up the pipline\n",
        "sentiment_pipeline_idf_rf = Pipeline(\n",
        "    stages=[\n",
        "            splitter\n",
        "            , sw_remover\n",
        "            , count_vec\n",
        "            , idf_cal\n",
        "            , label_string\n",
        "            , rf\n",
        "            ]\n",
        ")"
      ],
      "metadata": {
        "id": "1_1ZbAdqfEis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the parameters to tune\n",
        "parGrid = ParamGridBuilder() \\\n",
        "          .addGrid(idf_cal.minDocFreq, [5, 10]) \\\n",
        "          .addGrid(rf.numTrees, [20, 40]) \\\n",
        "          .addGrid(rf.maxDepth, [5, 4]) \\\n",
        "          .build()\n",
        "\n",
        "# Set up the cross validation\n",
        "crossVal_rf = CrossValidator(estimator=sentiment_pipeline_idf_rf,\n",
        "                          estimatorParamMaps=parGrid,\n",
        "                          evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
        "                          numFolds=10,\n",
        "                          seed=9165)"
      ],
      "metadata": {
        "id": "d-kkdLFHfKtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the process to the training data set\n",
        "\n",
        "cvModel_rf = crossVal_rf.fit(training)"
      ],
      "metadata": {
        "id": "chWOc_OFfP-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarise nicely the results of different parameter combinations\n",
        "\n",
        "for i in range(len(cvModel_rf.avgMetrics)):\n",
        "  myParam = parGrid[i]\n",
        "  myModel = \"Model parameters: \"\n",
        "  for key, value in myParam.items():\n",
        "    myModel += (key.name + '=' + str(value) + ' ')\n",
        "  print(myModel+\"has average accuracy: \"+str(cvModel_rf.avgMetrics[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyFGwZZmfTAu",
        "outputId": "0006c5f4-907d-4ef4-b384-2dfaabf137f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: minDocFreq=5 numTrees=20 maxDepth=5 has average accuracy: 0.6176726442161053\n",
            "Model parameters: minDocFreq=5 numTrees=20 maxDepth=4 has average accuracy: 0.5778559786526811\n",
            "Model parameters: minDocFreq=5 numTrees=40 maxDepth=5 has average accuracy: 0.5828305863093602\n",
            "Model parameters: minDocFreq=5 numTrees=40 maxDepth=4 has average accuracy: 0.5586308550759684\n",
            "Model parameters: minDocFreq=10 numTrees=20 maxDepth=5 has average accuracy: 0.5975431507188426\n",
            "Model parameters: minDocFreq=10 numTrees=20 maxDepth=4 has average accuracy: 0.6030019847501803\n",
            "Model parameters: minDocFreq=10 numTrees=40 maxDepth=5 has average accuracy: 0.5949051668218364\n",
            "Model parameters: minDocFreq=10 numTrees=40 maxDepth=4 has average accuracy: 0.5720242842635344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the best model to the test data set\n",
        "\n",
        "cv_prediction_rf = cvModel_rf.transform(test)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "cv_accuracy = evaluator.evaluate(cv_prediction_rf)\n",
        "print(\"Accuracy of the best Random Forest model with the test data is %g\"% (cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spRCvj3zfYuj",
        "outputId": "ce5d02fa-c89e-42dd-b878-ed2c85205ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the best Random Forest model with the test data is 0.637363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "sTlBr58IAl8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build up the pipeline/workflow for TF-IDF approach\n",
        "\n",
        "# Split the tweets into words\n",
        "splitter = feat.RegexTokenizer(\n",
        "    inputCol='reviewText'\n",
        "    , outputCol='text_split'\n",
        "    , pattern='\\s+'\n",
        ")\n",
        "\n",
        "# Remove stop words\n",
        "sw_remover = feat.StopWordsRemover(\n",
        "    inputCol=splitter.getOutputCol()\n",
        "    , outputCol='text_noSW'\n",
        ")\n",
        "\n",
        "# Count word frequency\n",
        "count_vec = feat.CountVectorizer(\n",
        "    inputCol=sw_remover.getOutputCol()\n",
        "    , outputCol='vector'\n",
        "    , vocabSize=5000\n",
        ")\n",
        "\n",
        "# Calculate IDF\n",
        "idf_cal = feat.IDF(\n",
        "    inputCol=count_vec.getOutputCol()\n",
        "    , outputCol='features'\n",
        "    , minDocFreq=5\n",
        ")\n",
        "\n",
        "# Prepare the target variable\n",
        "label_string = feat.StringIndexer(\n",
        "    inputCol = \"sentiment\"\n",
        "    , outputCol = \"label\"\n",
        ")\n",
        "\n",
        "# svm model\n",
        "lsvc = LinearSVC(maxIter=100)\n",
        "\n",
        "# Finally set up the pipline\n",
        "sentiment_pipeline_idf_lsvc = Pipeline(\n",
        "    stages=[\n",
        "            splitter\n",
        "            , sw_remover\n",
        "            , count_vec\n",
        "            , idf_cal\n",
        "            , label_string\n",
        "            , lsvc\n",
        "            ]\n",
        ")"
      ],
      "metadata": {
        "id": "QHZZTblxAsPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the parameters to tune\n",
        "parGrid = ParamGridBuilder() \\\n",
        "          .addGrid(count_vec.vocabSize, [3000, 5000]) \\\n",
        "          .addGrid(lsvc.regParam, [0.1, 5]) \\\n",
        "          .build()\n",
        "\n",
        "# Set up the cross validation\n",
        "crossVal_lsvc = CrossValidator(estimator=sentiment_pipeline_idf_lsvc,\n",
        "                          estimatorParamMaps=parGrid,\n",
        "                          evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
        "                          numFolds=10,\n",
        "                          seed=9165)"
      ],
      "metadata": {
        "id": "6zZPQ0aDB0IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the process to the training data set\n",
        "\n",
        "cvModel_lsvc = crossVal_lsvc.fit(training)"
      ],
      "metadata": {
        "id": "jEOgBkbuCXIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarise nicely the results of different parameter combinations\n",
        "\n",
        "for i in range(len(cvModel_lsvc.avgMetrics)):\n",
        "  myParam = parGrid[i]\n",
        "  myModel = \"Model parameters: \"\n",
        "  for key, value in myParam.items():\n",
        "    myModel += (key.name + '=' + str(value) + ' ')\n",
        "  print(myModel+\"has average accuracy: \"+str(cvModel_lsvc.avgMetrics[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UybxpIMAClzv",
        "outputId": "c0125564-f121-462b-ba8a-f8c3a712ace7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: vocabSize=3000 regParam=0.1 has average accuracy: 0.6930785095359377\n",
            "Model parameters: vocabSize=3000 regParam=5.0 has average accuracy: 0.6122528481791985\n",
            "Model parameters: vocabSize=5000 regParam=0.1 has average accuracy: 0.6930785095359377\n",
            "Model parameters: vocabSize=5000 regParam=5.0 has average accuracy: 0.6122528481791985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the best model to the test data set\n",
        "\n",
        "cv_prediction_lsvc = cvModel_lsvc.transform(test)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "cv_accuracy = evaluator.evaluate(cv_prediction_lsvc)\n",
        "print(\"Accuracy of the best svm model with the test data is %g\"% (cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjTa4S3sC4eG",
        "outputId": "1622a268-6bd1-4bfe-8cf9-e77ad21edbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the best Random Forest model with the test data is 0.703297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of model performance based on accuracy score:\n",
        "1. Logistic Regression - 0.736264\n",
        "2. Support Vector Machines - 0.7032\n",
        "3. Naive Bayes - 0.64835\n",
        "4. Random Forests - 0.6373\n",
        "\n",
        "The logistic regression was the best performing model while the random forest was the worst performing model for this dataset."
      ],
      "metadata": {
        "id": "Dzy3tJmGh__I"
      }
    }
  ]
}